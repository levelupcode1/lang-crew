#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import re
import csv
import uuid
from datetime import datetime

def generate_uuid():
    """Generate a unique UUID for each project"""
    return str(uuid.uuid4())

def clean_description(text):
    """Clean description by removing emojis and extra whitespace"""
    # Remove emoji and special characters at the beginning
    emoji_pattern = r'^[\sğŸ“‡ğŸ ğŸğŸªŸğŸ§â˜ï¸ğŸŒğŸğŸš€ğŸï¸âš¡ï¸ğŸ–±ï¸ğŸ–ï¸#ï¸âƒ£ğŸ¦€â˜•ğŸ”¥â›…ï¸ğŸ’¬ğŸ› ï¸ğŸ”’ğŸ›¡ï¸ğŸ¤–ğŸ”®ğŸŒ±ğŸ“ŠğŸ¦®ğŸ¬ğŸ“¹ğŸ”ğŸ“šğŸ’»ğŸ–¥ï¸ğŸ—„ï¸ğŸ’°ğŸ®ğŸ§ ğŸ—ºï¸ğŸ¯ğŸƒğŸŒğŸš†ğŸ”„ğŸ’¾ğŸ¨ğŸ•ï¸ğŸ›ï¸ğŸ“œâš™ï¸ğŸ“±ğŸ’¼ğŸ—‚ï¸ğŸµğŸ¸ğŸ¹ğŸ¤ğŸ§ğŸ¼ğŸ­ğŸªğŸ–¼ï¸ğŸ²ğŸƒğŸ€„ğŸ°ğŸ“•ğŸ“’ğŸ““ğŸ“”ğŸ“–ğŸ“—ğŸ“˜ğŸ“™ğŸ“šğŸ“ğŸ“ŒğŸ“ğŸ“ğŸ–‡ï¸ğŸ“ğŸ“âœ‚ï¸ğŸ—ƒï¸ğŸ—„ï¸ğŸ—‘ï¸ğŸ–Œï¸ğŸ–ï¸âœï¸âœ’ï¸ğŸ–‹ï¸ğŸ–Šï¸ğŸ“ğŸ’¼ğŸ“ğŸ“‚ğŸ—‚ï¸ğŸ“…ğŸ“†ğŸ—’ï¸ğŸ—“ï¸ğŸ“‡ğŸ“ˆğŸ“‰ğŸ“ŠğŸ“‹â‚¿ğŸ¦½ğŸ–ğŸ¦®ğŸ¤–ğŸ”®ğŸŒ±ğŸŒğŸ–±ï¸âš¡ï¸ğŸš€â›…ï¸ğŸ›ï¸ğŸ•ï¸ğŸ’¾ğŸ“œâš™ï¸ğŸ“±ğŸ’¼ğŸ—‚ï¸ğŸµğŸ¸ğŸ¹ğŸ¤ğŸ§ğŸ¼ğŸ­ğŸªğŸ–¼ï¸ğŸ²ğŸƒğŸ€„ğŸ°\s-]+' 
    text = re.sub(emoji_pattern, '', text)
    # Remove multiple spaces and newlines
    text = re.sub(r'\s+', ' ', text)
    return text.strip()

def parse_projects(content, category_name):
    """Parse project entries from category content"""
    projects = []
    lines = content.split('\n')
    
    for line in lines:
        # Skip empty lines and non-project lines
        if not line.strip().startswith('- ['):
            continue
            
        # Extract project name and URL
        match = re.match(r'- \[([^\]]+)\]\(([^\)]+)\)', line)
        if not match:
            continue
            
        project_name = match.group(1).strip()
        url = match.group(2).strip()
        
        # Skip if not a valid URL
        if not url.startswith('http'):
            continue
            
        # Extract description (everything after the link)
        after_link = line[match.end():]
        description = clean_description(after_link)
        
        # Create project entry
        project = {
            'uuid': generate_uuid(),
            'name': project_name.replace('@', '').replace('/', '-'),
            'title': project_name,
            'description': description[:500] if description else '',
            'url': url,
            'category': category_name,
            'status': 'active',
            'created_at': 'NOW()'
        }
        projects.append(project)
    
    return projects

def write_csv(projects, filename):
    """Write projects to CSV file"""
    if not projects:
        print(f"No projects to write for {filename}")
        return
        
    headers = ['uuid', 'name', 'title', 'description', 'url', 'category', 'status', 'created_at']
    
    with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=headers)
        writer.writeheader()
        writer.writerows(projects)
    
    print(f"Written {len(projects)} projects to {filename}")

def main():
    # Read the README file
    with open('/Volumes/MacPro16/projects/proj-langcrew/lang-crew/data/README-ko.md', 'r', encoding='utf-8') as f:
        content = f.read()
    
    # Define categories to process
    categories = {
        'browser_automation': {
            'header': '### ğŸ“‚ <a name="browser-automation"></a>ë¸Œë¼ìš°ì € ìë™í™”',
            'filename': 'projects_browser_automation.csv'
        },
        'art_and_culture': {
            'header': '### ğŸ¨ <a name="art-and-culture"></a>ì˜ˆìˆ  ë° ë¬¸í™”',
            'filename': 'projects_art_and_culture.csv'
        },
        'cloud_platforms': {
            'header': '### â˜ï¸ <a name="cloud-platforms"></a>í´ë¼ìš°ë“œ í”Œë«í¼',
            'filename': 'projects_cloud_platforms.csv'
        },
        'command_line': {
            'header': '### ğŸ–¥ï¸ <a name="command-line"></a>ì»¤ë§¨ë“œ ë¼ì¸',
            'filename': 'projects_command_line.csv'
        },
        'communication': {
            'header': '### ğŸ’¬ <a name="communication"></a>ì»¤ë®¤ë‹ˆì¼€ì´ì…˜',
            'filename': 'projects_communication.csv'
        },
        'customer_data_platforms': {
            'header': '### ğŸ‘¤ <a name="customer-data-platforms"></a>ê³ ê° ë°ì´í„° í”Œë«í¼',
            'filename': 'projects_customer_data_platforms.csv'
        },
        'data_platforms': {
            'header': '### ğŸ“Š <a name="data-platforms"></a>ë°ì´í„° í”Œë«í¼',
            'filename': 'projects_data_platforms.csv'
        },
        'databases': {
            'header': '### ğŸ—„ï¸ <a name="databases"></a>ë°ì´í„°ë² ì´ìŠ¤',
            'filename': 'projects_databases.csv'
        },
        'developer_tools': {
            'header': '### ğŸ’» <a name="developer-tools"></a>ê°œë°œì ë„êµ¬',
            'filename': 'projects_developer_tools.csv'
        },
        'data_science_tools': {
            'header': '### ğŸ§® ë°ì´í„° ê³¼í•™ ë„êµ¬',
            'filename': 'projects_data_science_tools.csv'
        },
        'file_systems': {
            'header': '### ğŸ“‚ <a name="file-systems"></a>íŒŒì¼ ì‹œìŠ¤í…œ',
            'filename': 'projects_file_systems.csv'
        },
        'finance_fintech': {
            'header': '### ğŸ’° <a name="finance--fintech"></a>ê¸ˆìœµ ë° í•€í…Œí¬',
            'filename': 'projects_finance_fintech.csv'
        },
        'gaming': {
            'header': '### ğŸ® <a name="gaming"></a>ê²Œì„',
            'filename': 'projects_gaming.csv'
        },
        'knowledge_memory': {
            'header': '### ğŸ§  <a name="knowledge--memory"></a>ì§€ì‹ ë° ë©”ëª¨ë¦¬',
            'filename': 'projects_knowledge_memory.csv'
        },
        'location_services': {
            'header': '### ğŸ—ºï¸ <a name="location-services"></a>ìœ„ì¹˜ ì„œë¹„ìŠ¤',
            'filename': 'projects_location_services.csv'
        },
        'marketing': {
            'header': '### ğŸ¯ <a name="marketing"></a>ë§ˆì¼€íŒ…',
            'filename': 'projects_marketing.csv'
        },
        'monitoring': {
            'header': '### ğŸ“Š <a name="monitoring"></a>ëª¨ë‹ˆí„°ë§',
            'filename': 'projects_monitoring.csv'
        },
        'search': {
            'header': '### ğŸ” <a name="search"></a>ê²€ìƒ‰',
            'filename': 'projects_search.csv'
        },
        'security': {
            'header': '### ğŸ”’ <a name="security"></a>ë³´ì•ˆ',
            'filename': 'projects_security.csv'
        },
        'sports': {
            'header': '### ğŸƒ <a name="sports"></a>ìŠ¤í¬ì¸ ',
            'filename': 'projects_sports.csv'
        },
        'translation_services': {
            'header': '### ğŸŒ <a name="translation-services"></a>ë²ˆì—­ ì„œë¹„ìŠ¤',
            'filename': 'projects_translation_services.csv'
        },
        'travel_and_transportation': {
            'header': '### ğŸš† <a name="travel-and-transportation"></a>ì—¬í–‰ ë° êµí†µ',
            'filename': 'projects_travel_and_transportation.csv'
        },
        'version_control': {
            'header': '### ğŸ”„ <a name="version-control"></a>ë²„ì „ ê´€ë¦¬',
            'filename': 'projects_version_control.csv'
        },
        'other_tools_and_integrations': {
            'header': '### ğŸ› ï¸ <a name="other-tools-and-integrations"></a>ê¸°íƒ€ ë„êµ¬ ë° í†µí•©',
            'filename': 'projects_other_tools_and_integrations.csv'
        }
    }
    
    # Process each category
    for category_key, category_info in categories.items():
        print(f"\nProcessing category: {category_key}")
        
        # Find the start of the category
        start_idx = content.find(category_info['header'])
        if start_idx == -1:
            print(f"  Category not found: {category_info['header']}")
            continue
        
        # Find the end of the category (next ### or ## or end of file)
        end_idx = content.find('\n###', start_idx + 1)
        if end_idx == -1:
            end_idx = content.find('\n##', start_idx + 1)
            if end_idx == -1:
                end_idx = len(content)
        
        # Extract category content
        category_content = content[start_idx:end_idx]
        
        # Parse projects
        projects = parse_projects(category_content, category_key)
        
        # Write to CSV
        output_path = f'/Volumes/MacPro16/projects/proj-langcrew/lang-crew/data/{category_info["filename"]}'
        write_csv(projects, output_path)

if __name__ == '__main__':
    main()
